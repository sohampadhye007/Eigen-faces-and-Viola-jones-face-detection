# -*- coding: utf-8 -*-
"""M22RM007_Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kQ1VELNe8hAYcB4XZgMiPKW_cj1otXD9

#Soham Padhye (M22RM007)
#Load the CIFAR-10 dataset using TensorFlow:
"""

import tensorflow as tf

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()
print(train_images.shape)
print(test_images.shape)

"""# Preprocess the images by scaling their pixel values to the range of [0, 1]"""

train_images = train_images / 255.0
test_images = test_images / 255.0

"""# Define the CNN model to extract features from the images"""

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), padding='same'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10, activation='softmax')
])

"""# Compile the model with the appropriate loss function and optimizer"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""# Train the model on the CIFAR-10 dataset"""

model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))
# Save the model to a file
model.save('Image_searchEngine.h5')

"""#Extract features from the images using the trained CNN model"""

train_features = model.predict(train_images, verbose=1)
test_features = model.predict(test_images, verbose=1)

"""# Cluster the features using KMeans algorithm to create the Visual BoW vocabulary"""

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=100)
kmeans.fit(train_features)

vocab = kmeans.cluster_centers_

"""# Build a function to compute the histogram of features for each image using the Visual BoW vocabulary"""

import numpy as np

def get_histogram(features, vocab):
    distances = np.sqrt(((features - vocab[:, np.newaxis])**2).sum(axis=2))
    nearest = np.argmin(distances, axis=0)
    hist, _ = np.histogram(nearest, bins=range(len(vocab)+1))
    return hist

"""# Compute the histogram of features for each image in the dataset"""

train_histograms = []
test_histograms = []

for i in range(len(train_images)):
    hist = get_histogram(train_features[i], vocab)
    train_histograms.append(hist)

for i in range(len(test_images)):
    hist = get_histogram(test_features[i], vocab)
    test_histograms.append(hist)

"""# Build a function to retrieve the top-5 similar images for a given query image"""

def retrieve_similar_images(query_image, train_images, train_histograms):
    query_feature = model.predict(query_image[np.newaxis])[0]
    query_hist = get_histogram(query_feature, vocab)
    distances = np.sqrt(((query_hist - np.array(train_histograms))**2).sum(axis=1))
    sorted_indices = np.argsort(distances)
    similar_images = train_images[sorted_indices[:5]]
    similar_img_labels = train_labels[sorted_indices[:5]]
    return similar_images,similar_img_labels

"""# Test the image search engine by providing a query image and retrieving the top-5 similar images"""

import matplotlib.pyplot as plt
import cv2

# Select a query image from the test set
query_image = cv2.imread('ship.jpg')
query_image=cv2.resize(query_image,(32,32))

# Retrieve the top-5 similar images
similar_images,similar_img_labels = retrieve_similar_images(query_image, train_images, train_histograms)

# Plot the query image and the similar images
fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(20, 20))

axes[0].imshow(query_image)
axes[0].set_title("Query Image")
for i in range(5):
    axes[i+1].imshow(similar_images[i])
    axes[i+1].set_title(f"Similar Image {i+1},Label:{similar_img_labels[i]}")
plt.show()

from sklearn.metrics import precision_recall_curve, average_precision_score
import matplotlib.pyplot as plt
import tensorflow as tf

# Load the model from the file
model = tf.keras.models.load_model('Image_searchEngine.h5')

# Make predictions on the test data
y_prob = model.predict(test_images)

# Calculate precision and recall for different probability thresholds for each class
aps = []
for i in range(10):
    y_test_one_vs_all = np.zeros_like(test_labels)
    y_test_one_vs_all[test_labels == i] = 1
    ap = average_precision_score(y_test_one_vs_all, y_prob[:, i])
    aps.append(ap)

# Calculate the average AP over all classes
mean_ap = np.mean(aps)

# Plot the PR curve for class 1
precision, recall, thresholds = precision_recall_curve(y_test_one_vs_all, y_prob[:, 1])
print(f"Recall {recall}")
print(f"precision {precision}")
plt.plot(recall, precision)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('PR Curve (AP = %0.2f)' % aps[1])
plt.show()

